-------------- PART A ------------------
I have implemented an artifical neural network,	which can use either Quasi-Newton- or simplex-minimisation.
I will test both of these implementations.

Final parameters: Quasi-Newton
-1.73005333946236   -0.0925192704150136   1.0871761971004   
1.03400775256729   0.444430065630823   0.551306355502376   
1.08364990257695   2.55633849930181   1.57804959872756   

Final parameters: Simplex
-1.28634334574757   -0.0916356280401887   1.09749118767287   
0.961503658527764   0.502115886393471   0.82454389909518   
2.2760172035892   3.70585792857955   2.711085334384   
The plots of the trained networks are in plotA.svg.
The simplex method seems to be much more robust and stable than the qnewton.
Whilst the qnewton method is very sensitive to precision the simplex simply 
always returns something reasonable.
Both networks are however very nice compared to the analytical function, and seems 
 to be in fine agreement with the parameters.
